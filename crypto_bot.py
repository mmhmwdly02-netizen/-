import feedparser
import telebot
import time
import schedule
import os
import requests
from datetime import datetime
from html.parser import HTMLParser

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOKEN = "8531181643:AAGYZgnY46GzrelXkUPdFrCYOg0xetJm-5Y"
CHANNEL = "@sdghd43"

RSS_SOURCES = [
    "https://cointelegraph.com/rss",
    "https://www.coindesk.com/arc/outboundfeeds/rss/",
    "https://cryptoslate.com/feed/",
    "https://www.bitcoinmagazine.com/feed",
]

POSTED_FILE = "posted.txt"
SCHEDULED_TIMES = ["01:47"]  # 4 Ù…Ø±Ø§Øª ÙŠÙˆÙ…ÙŠÙ‹Ø§

bot = telebot.TeleBot(TOKEN)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def translate_text(text):
    """ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Translate API Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ"""
    try:
        if len(text) > 5000:
            text = text[:5000]
        
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            'client': 'gtx',
            'sl': 'en',
            'tl': 'ar',
            'dt': 't',
            'q': text
        }
        
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            result = response.json()
            translated = ''.join([item[0] for item in result[0] if item[0]])
            return translated if translated else text
        else:
            return text
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©: {e}")
        return text

def get_article_content(link):
    """Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(link, timeout=10, headers=headers)
        if response.status_code == 200:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø¨Ø³ÙŠØ· Ù…Ù† HTML
            class TextExtractor(HTMLParser):
                def __init__(self):
                    super().__init__()
                    self.text = []
                    self.in_paragraph = False
                
                def handle_starttag(self, tag, attrs):
                    if tag == 'p':
                        self.in_paragraph = True
                
                def handle_endtag(self, tag):
                    if tag == 'p':
                        self.in_paragraph = False
                
                def handle_data(self, data):
                    if self.in_paragraph and data.strip():
                        self.text.append(data.strip())
            
            parser = TextExtractor()
            parser.feed(response.text)
            
            # Ø¯Ù…Ø¬ Ø§Ù„ÙÙ‚Ø±Ø§Øª ÙˆØ£Ø®Ø° Ø£ÙˆÙ„ 3-4 ÙÙ‚Ø±Ø§Øª
            paragraphs = parser.text[:4]
            content = ' '.join(paragraphs)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø·ÙˆÙ„ (Ø­ÙˆØ§Ù„ÙŠ 800-1000 Ø­Ø±Ù)
            if len(content) > 1000:
                content = content[:1000] + "..."
            
            return content if content else None
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„: {e}")
        return None

def already_posted(link):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø´Ø± Ø§Ù„Ø®Ø¨Ø± Ø³Ø§Ø¨Ù‚Ø§Ù‹"""
    if not os.path.exists(POSTED_FILE):
        return False
    with open(POSTED_FILE, "r", encoding="utf-8") as f:
        return link.strip() in f.read().splitlines()

def save_posted(link):
    """Ø­ÙØ¸ Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ù†Ø´ÙˆØ±"""
    with open(POSTED_FILE, "a", encoding="utf-8") as f:
        f.write(link.strip() + "\n")

def fetch_news():
    """Ø¬Ù„Ø¨ Ø®Ø¨Ø± Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ø¹ Ø§Ù„ØªÙ†ÙˆØ¹ Ø¨ÙŠÙ† Ø§Ù„Ù…ØµØ§Ø¯Ø±"""
    import random
    
    # Ø®Ù„Ø· Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙ†ÙˆØ¹
    shuffled_sources = RSS_SOURCES.copy()
    random.shuffle(shuffled_sources)
    
    all_entries = []
    
    # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±
    for source in shuffled_sources:
        try:
            print(f"ğŸ” ÙØ­Øµ Ø§Ù„Ù…ØµØ¯Ø±: {source}")
            feed = feedparser.parse(source)
            for entry in feed.entries:
                # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ù„Ù…ØµØ¯Ø± Ù„ÙƒÙ„ Ø®Ø¨Ø±
                entry.source_url = source
                all_entries.append(entry)
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ØµØ¯Ø± {source}: {e}")
            continue
    
    if not all_entries:
        return None
    
    # Ø®Ù„Ø· Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙ†ÙˆØ¹
    random.shuffle(all_entries)
    
    # Ø£ÙˆÙ„Ø§Ù‹: Ø­Ø§ÙˆÙ„ ØªÙ„Ø§Ù‚ÙŠ Ø®Ø¨Ø± Ø¬Ø¯ÙŠØ¯ Ù„Ù… ÙŠÙ†Ø´Ø±
    for entry in all_entries:
        if not already_posted(entry.link):
            return entry
    
    # Ø«Ø§Ù†ÙŠØ§Ù‹: Ù„Ùˆ ÙƒÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù†Ø´ÙˆØ±Ø©ØŒ Ø®Ø° Ø®Ø¨Ø± Ø¹Ø´ÙˆØ§Ø¦ÙŠ (Ø­ØªÙ‰ Ù„Ùˆ Ù‚Ø¯ÙŠÙ…)
    print("âš ï¸ ÙƒÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù†Ø´ÙˆØ±Ø©ØŒ Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ù†Ø´Ø± Ø®Ø¨Ø± Ù‚Ø¯ÙŠÙ…...")
    return random.choice(all_entries) if all_entries else None

def format_message(title, link, source_name, summary=""):
    """ØªÙ†Ø³ÙŠÙ‚ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø¨Ø± Ø¨Ø´ÙƒÙ„ Ø¬Ø±ÙŠØ¯Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©"""
    
    # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
    print("ğŸ”¤ Ø¬Ø§Ø±ÙŠ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù†...")
    title_ar = translate_text(title)
    
    # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ù„Ø®Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯
    summary_ar = ""
    if summary:
        print("ğŸ”¤ Ø¬Ø§Ø±ÙŠ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰...")
        summary_ar = translate_text(summary)
    
    # Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ
    now = datetime.now()
    date_ar = now.strftime("%d/%m/%Y")
    time_ar = now.strftime("%I:%M %p")
    
    # Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙƒØ¬Ø±ÙŠØ¯Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©
    message = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ   ğŸ“° *ØµØ­ÙŠÙØ© Ø§Ù„ÙƒØ±ÙŠØ¨ØªÙˆ*   â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›

*{title_ar}*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„Ø®Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯
    if summary_ar:
        message += f"""ğŸ“„ *Ø§Ù„ØªÙØ§ØµÙŠÙ„:*

{summary_ar}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
    
    message += f"""ğŸ“Œ *Ø§Ù„Ù…ØµØ¯Ø±:* {source_name}
ğŸ“… *Ø§Ù„ØªØ§Ø±ÙŠØ®:* {date_ar}
ğŸ• *Ø§Ù„ÙˆÙ‚Øª:* {time_ar}

ğŸ”— [Ø§Ù‚Ø±Ø£ Ø§Ù„Ø®Ø¨Ø± ÙƒØ§Ù…Ù„Ø§Ù‹]({link})

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’ _ØªØ§Ø¨Ø¹Ù†Ø§ Ù„Ø¢Ø®Ø± Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„Ù… Ø§Ù„ÙƒØ±ÙŠØ¨ØªÙˆ_
    """
    
    return message

def get_source_name(link):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…ØµØ¯Ø± Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
    if "cointelegraph" in link:
        return "CoinTelegraph"
    elif "coindesk" in link:
        return "CoinDesk"
    elif "cryptoslate" in link:
        return "CryptoSlate"
    elif "bitcoinmagazine" in link:
        return "Bitcoin Magazine"
    elif "decrypt.co" in link:
        return "Decrypt"
    else:
        return "Ù…ØµØ¯Ø± Ø®Ø§Ø±Ø¬ÙŠ"

def publish_news():
    """Ù†Ø´Ø± Ø®Ø¨Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ù†Ø§Ø© (Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ù‚Ø¯ÙŠÙ…)"""
    print(f"\n{'='*50}")
    print(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø®Ø¨Ø§Ø±...")
    print(f"â° Ø§Ù„ÙˆÙ‚Øª: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    news = fetch_news()
    
    if news is None:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø± Ù…ØªØ§Ø­Ø© Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±")
        print(f"{'='*50}\n")
        return
    
    source_name = get_source_name(news.link)
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù‚Ø§Ù„
    print("ğŸ“„ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„...")
    summary = get_article_content(news.link)
    
    if summary:
        print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„Ø®Øµ ({len(summary)} Ø­Ø±Ù)")
    else:
        print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØµÙ Ù…Ù† RSS")
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØµÙ Ù…Ù† RSS ÙƒØ¨Ø¯ÙŠÙ„
        summary = getattr(news, 'summary', '')
    
    message = format_message(news.title, news.link, source_name, summary)
    
    try:
        bot.send_message(
            CHANNEL, 
            message, 
            parse_mode='Markdown',
            disable_web_page_preview=False
        )
        save_posted(news.link)
        print(f"âœ… ØªÙ… Ù†Ø´Ø± Ø®Ø¨Ø± Ù…Ù† {source_name}")
        print(f"ğŸ“ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {news.title[:50]}...")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø´Ø±: {e}")
    
    print(f"{'='*50}\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("\n" + "="*50)
    print("ğŸ¤– Ø¨ÙˆØª Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙƒØ±ÙŠØ¨ØªÙˆ - ØªÙ… Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
    print("="*50)
    print(f"ğŸ“¢ Ø§Ù„Ù‚Ù†Ø§Ø©: {CHANNEL}")
    print(f"â° Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù†Ø´Ø±: {', '.join(SCHEDULED_TIMES)}")
    print(f"ğŸ“¡ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø±: {len(RSS_SOURCES)}")
    print("="*50 + "\n")
    
    # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ø§Ù…
    for t in SCHEDULED_TIMES:
        schedule.every().day.at(t).do(publish_news)
        print(f"â° ØªÙ… Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù†Ø´Ø± ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø©: {t}")
    
    print("\nğŸ”„ Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†... Ø§Ø¶ØºØ· Ctrl+C Ù„Ù„Ø¥ÙŠÙ‚Ø§Ù\n")
    
    # Ù†Ø´Ø± Ø®Ø¨Ø± Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
    print("ğŸ§ª Ø¬Ø§Ø±ÙŠ Ù†Ø´Ø± Ø®Ø¨Ø± ØªØ¬Ø±ÙŠØ¨ÙŠ...")
    publish_news()
    
    # Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    try:
        while True:
            schedule.run_pending()
            time.sleep(30)  # ÙØ­Øµ ÙƒÙ„ 30 Ø«Ø§Ù†ÙŠØ©
    except KeyboardInterrupt:
        print("\n\nâŒ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨ÙˆØª Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        print("="*50 + "\n")

if __name__ == "__main__":
    main()